/* BUGS:

Due to now JavaCC handles EOF, EOF cannot terminate a single-line comment

The current method of computing follow sets is wrong, but it emulates
the behavior of the previous system.

*/

/* DISCUSSION ITEMS:

Is one of "priorities" or "priority" depricated/preferred? If so, should the other trigger a warning?

The PriorityBlockExtend class has an "assoc" field. Does this need to be set?  What should it be set to?

inconsistency in whether comments are inside rule and lexical or not

"List" is not a keyword (!)

Why "Keyword [ RL ] : BUBBLE" instead of "Keyword [ RL ] BUBBLE"?

Some way to generalize FUNCTIONID and TupleProd?

Strings in KIL should be enum

Tabs in comments should not be translated to spaces

*/


/***** IDIOMS USED IN THIS FILE *****

PARAMETERS AND RETURN VALUES

There are two styles of writing productions that are used in this
grammar.  The first simply returns the parsed object.  For example,
the 'Bubble' production returns a String.  The second takes a
parameter representing the parent node that the production should add
a child to.  For example, the 'Require' production returns 'void' and
takes a 'List<DefinitionItem>' as parameter.  Once successfully
parsed, 'Require' object is added to this 'List'.

In different cases, one or the other style is easier to use so the
code freely mixes between the two styles.

SOURCE LOCATION INFORMATION

At the start of each production, we call 'startLoc()'.  This function
queries the start location of the next token and returns part of the
String that will be used to represent the location of the current
production.

At the end of each production, we call 'markLoc' before returning.
This function takes as parameter the String returned by 'startLoc' and
the 'ASTNode'.  It then queries the last token consumed for its end
position and adds an 'location' attribute to the 'ASTNode' for the
given start and end locations.  Finally, it returns the 'ASTNode' that
was passed to it.  The reason it returns the 'ASTNode' is as a
convenience so you can write things like the following without having
to save the newly created 'ASTNode' to a variable:

  return markLoc(loc, new Sort(image()));

For single token 'ASTNode' objects, the function 'tokenLoc' computes
both the start and end location from the start and end location of the
last token consumed.  The only parameter that it takes is the
'ASTNode' that this start location is to return.  Like 'markLoc' this
function also returns the given 'ASTNode'.

The final complication is that since a 'Bubble' is parsed by a second
pass in the 'makeStringSentence' method we have to store an offset to
the source locations that is used in the second pass of parsing.
These offsets are stored in 'beginLine', 'beginColumn'.

COMMENTS

Comments are handled by calling the 'comment()' function.  If we are
not in the process of parsing a 'Module' then the 'module' field will
be 'null' and the comment will be added to the 'List<DefinitionItem>'
that is stored in the 'items' field.  On the other hand, if we are in
the process of parsing a 'Module' then the 'module' field will not be
'null' and the comment will be added to the current 'module'.  Note
that the 'Module' production has to be careful to set the 'module'
field correctly.

*/


/***** LEXING COMPLICATIONS *****

*** LEXING STATES ***

The lexer rules for a K file differ in different parts of the file so
we have to switch between lexer states.

States:
 - Primary States: (these switch on specific tokens)
   - DEFAULT
   - BUBBLE_STATE: rhs of "rule" (SPECIAL_TOKEN includes whitespace)
   - KLABEL_STATE: rhs of priority or associativity declarations

 - Secondary States: (switch based on grammar context)
   - ATTR_STATE: used in body of Attributes (SPECIAL_TOKEN include whitespace)
   - TAG_STATE: used in body of Tags
   - REGEX_STATE: used in body of RegEx (SPECIAL_TOKEN includes whitespace)
   - GROUP_STATE: used in body of Group (i.e., a character class)

 - Tertiary States: (switch for one token)
   - MODNAME_STATE: used after "module", "interface" or "imports"

To avoid clutter we make separate token declarations for only those
tokens that are used in multiple places (in the DEFAULT state).

*** IDENTIFIER FORMS ***

UPPER_ID ::= "#"?["A"-"Z"]["a"-"z", "A"-"Z", "0"-"9"]*
LOWER_ID ::= "#"?["a"-"z"]["a"-"z", "A"-"Z", "0"-"9"]*

UPPER_ID (used in List{_})
UPPER_ID | LOWER_ID (used in FUN(...))

SortID ::= UPPER_ID ("{" UPPERID "}")?
  -- but no '#' allowed at front?

MOD_NAME ::= "#"?{[a-z0-9A-Z_]+ "-"}+

KLABEL ::= anything (other than "<")

ID (RegEx): [a-zA-Z][a-zA-Z0-9]*

KEY(Attribute): [a-z1-9][a-zA-Z0-9-]*

"List" is both "UPPER_ID" and custom operator

RL ::= ~[\[\]\_\ \n\r\t]+

*/

options {
  STATIC = false;
  UNICODE_INPUT = true;
  SUPPORT_CLASS_VISIBILITY_PUBLIC = false;
  TOKEN_MANAGER_USES_PARSER = true;
  // FORCE_LA_CHECK = true; // Useful for development, but causes a warning in Production()
}

PARSER_BEGIN(Basic)
package org.kframework.parser.basic;

import org.kframework.kil.ASTNode;
import org.kframework.kil.Attribute;
import org.kframework.kil.Attributes;
import org.kframework.kil.DefinitionItem;
import org.kframework.kil.Import;
import org.kframework.kil.KLabelConstant;
import org.kframework.kil.Lexical;
import org.kframework.kil.LiterateComment.LiterateCommentType;
import org.kframework.kil.LiterateDefinitionComment;
import org.kframework.kil.LiterateModuleComment;
import org.kframework.kil.Module;
import org.kframework.kil.ModuleItem;
import org.kframework.kil.PriorityBlock;
import org.kframework.kil.PriorityBlockExtended;
import org.kframework.kil.PriorityExtended;
import org.kframework.kil.PriorityExtendedAssoc;
import org.kframework.kil.Production;
import org.kframework.kil.ProductionItem;
import org.kframework.kil.Require;
import org.kframework.kil.Restrictions;
import org.kframework.kil.Sort;
import org.kframework.kil.StringSentence;
import org.kframework.kil.Syntax;
import org.kframework.kil.Terminal;
import org.kframework.kil.UserList;
import org.kframework.kil.loader.Context;

import org.kframework.utils.StringUtil;
import org.kframework.utils.errorsystem.KException.ExceptionType;
import org.kframework.utils.errorsystem.KException.KExceptionGroup;
import org.kframework.utils.errorsystem.KException;
import org.kframework.utils.general.GlobalSettings;

import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

// Comments get processed in an odd order that may cause them to be
// out of order.  Thus we sort module items by their *end* position so
// that comments within a module item are put before the module item
// but commends between module items are put between the module items.
class EndPositionComparator implements Comparator<ModuleItem> {
  public int compare(ModuleItem o1, ModuleItem o2) {
    String[] s1 = o1.getLocation().split("[\\(,\\)]");
    int endLine1 = Integer.parseInt(s1[3]), endCol1 = Integer.parseInt(s1[4]);
    String[] s2 = o2.getLocation().split("[\\(,\\)]");
    int endLine2 = Integer.parseInt(s2[3]), endCol2 = Integer.parseInt(s2[4]);
    if (endLine1 < endLine2 || endLine1 == endLine2 && endCol1 < endCol2) return -1;
    if (endLine1 > endLine2 || endLine1 == endLine2 && endCol1 > endCol2) return 1;
    return 0;
  }
}

public class Basic {
  private String filename;
  private List<DefinitionItem> items = new ArrayList<DefinitionItem>();;
  private Module module = null;
  private int beginLine, beginColumn;
  private Context context;

  /** Parses a given string that was read from 'filename'. */
  public static List<DefinitionItem> parse(
    String filename, String string, Context context) {
    Basic parser = new Basic(new StringReader(string));
    parser.filename = filename;
    parser.context = context;
    try {
      return parser.Start();
    } catch (ParseException e) {
      // TODO: report location
      GlobalSettings.kem.register(new KException(
        ExceptionType.ERROR, KExceptionGroup.OUTER_PARSER, e.getMessage(), filename, null));
      return new ArrayList<DefinitionItem>();
    } catch (TokenMgrError e) {
      GlobalSettings.kem.register(new KException(
        ExceptionType.ERROR, KExceptionGroup.OUTER_PARSER, e.getMessage(), filename, null));
      return new ArrayList<DefinitionItem>();
    }
  }

  /** Parses a given string that was fead from 'filename' as a list of
  attributes.  Note that the source position in the returned result is
  relative to the String. */
  public static Attributes parseAttributes(String string, String filename) throws ParseException {
    Basic parser = new Basic(new StringReader(string));
    parser.filename = filename;
    parser.module = null;
    parser.items = new ArrayList<DefinitionItem>();
    StringSentence ss = new StringSentence("", "", "", "");
    try {
      parser.AttributesBodyEOF(ss);
    } catch (TokenMgrError e) {
      throw new ParseException(e.getMessage());
    }
    return ss.getAttributes();
  }

  /***** Source Location *****/
  /** Returns the start location of the next token */
  private String startLoc() {
    Token t = getToken(1);
    return "("+ (beginLine + t.beginLine) + "," +
                (beginColumn + t.beginColumn);
  }

  /** Marks 'node' with the start position in 'locPrefix' and the end
  position of the last token.  Returns 'node' (which simplifies many
  uses of this function).
  */
  private <T extends ASTNode> T markLoc(String locPrefix, T node) {
    return markLocExplicit(
      locPrefix + "," + token.endLine + "," + token.endColumn + ")", node);
  }

  /** Marks 'node' with the location in 'loc'.Returns 'node' (which
  simplifies many uses of this function).
  */
  private <T extends ASTNode> T markLocExplicit(String loc, T node) {
    node.setFilename(filename);
    node.setLocation(loc);
    return node;
  }

  /** Marks 'node' with the start and end location of the last token.
  Returns 'node' (which simplifies many uses of this function).
  */
  private <T extends ASTNode> T tokenLoc(T node) {
    return markLoc("(" + (beginLine + token.beginLine) + "," +
                         (beginColumn + token.beginColumn), node);
  }

  /***** Token Processing *****/

  /** Returns the string of the last token. */
  private String image() {
    return token.image;
  }

  /** Returns the concatenation of the immediately preceding special tokens. */
  private String special() {
    StringBuilder sb = new StringBuilder();
    Token t = token;

    while ((t = t.specialToken) != null) {
      sb.insert(0, t.image);
    }

    return sb.toString();
  }

  /** Returns the concatenation of the immediately preceding special
  tokens and regular token. */
  private String specialAndImage() { return special() + image(); }

  /***** Misc Operations *****/

  /** Switches the lexer to a new state */
  private void SwitchTo(int state) {
    token_source.SwitchTo(state);
  }

  /** Adds a comment to the current module or definition list */
  void comment(Token token) {
    String str = token.image;
    if (str.startsWith("//"))
      str = str.substring(2, str.length() - 1); // remove // and \n from beginning and end
    else
      str = str.substring(2, str.length() - 2); // remove /* and */ from beginning and end

    LiterateCommentType lcType = LiterateCommentType.COMMON;

    if (str.startsWith("@")) {
      lcType = LiterateCommentType.LATEX;
      str = str.substring(1);
    } else if (str.startsWith("!")) {
      lcType = LiterateCommentType.PREAMBLE;
      str = str.substring(1);
    }

    String loc = "("+
      token.beginLine+","+token.beginColumn+","+
      token.endLine+","+token.endColumn+")";

    if (module == null) {
      items.add(markLocExplicit(loc, new LiterateDefinitionComment(str, lcType)));
    } else {
      module.appendModuleItem(markLocExplicit(loc, new LiterateModuleComment(str, lcType)));
    }
  }

  static final private Pattern pattern = Pattern.compile(
    "(?s)\\s*\\[\\s*([^\\[\\]\\_\\ \\n\\r\\t]+)\\s*\\]\\s*:\\s*(.*)");

  /** Does the extra parsing needed to create a StringSentence */
  private StringSentence makeStringSentence(String type, String str,
      int sentenceBeginLine, int sentenceBeginColumn) {
    // First, try to parse any rule label at the start
    Matcher matcher = pattern.matcher(str);
    String content, label;
    int offset = 0;
    if (matcher.matches()) {
      content = matcher.group(2);
      label = matcher.group(1);
      offset = matcher.start(2);
    } else {
      content = str;
      label = "";
      offset = 0;
    }

    String location = "("+offsetLine(str, sentenceBeginLine, sentenceBeginColumn, offset)+
                      ","+offsetColumn(str, sentenceBeginLine, sentenceBeginColumn, offset)+")";
    // Second, try to parse any attributes at the end.
    // Unfortunately, attributes after a StringSentence are not
    // parsable by an LR parser so we have to try parsing at spots
    // where we think the attributes might start.
    for (int i = content.lastIndexOf('[');
         i >= 0;
         i = content.lastIndexOf('[', i - 1)) {
      Basic parser = new Basic(new StringReader(content.substring(i)));
      parser.filename = this.filename;
      parser.module = this.module;
      parser.items = this.items;
      parser.beginLine = offsetLine(str, sentenceBeginLine, sentenceBeginColumn, offset + i);
      parser.beginColumn = offsetLine(str, sentenceBeginLine, sentenceBeginColumn, offset + i);
      try {
        StringSentence ss = new StringSentence(content.substring(0, i), location, type, label);
        parser.AttributesEOF(ss);
        return ss;
      } catch (ParseException e) {
        /* Our guess was wrong. Try another position. */
      } catch (TokenMgrError e) {
        /* Our guess was wrong. Try another position. */
      }
    }
    return new StringSentence(content, location, type, label);
  }

  private int offsetLine(String str, int line, int column, int index)
  {
    if (index == 0) return line;
    SimpleCharStream s = new SimpleCharStream(new StringReader(str), line, column);
    try {
      for (int i = 0; i <= index; i++) { s.readChar(); }
    } catch (IOException e) { /* Impossible */ e.printStackTrace(); System.exit(1); }
    return s.getEndLine();
  }

  private int offsetColumn(String str, int line, int column, int index)
  {
    if (index == 0) return column;
    SimpleCharStream s = new SimpleCharStream(new StringReader(str), line, column);
    try {
      for (int i = 0; i <= index; i++) { s.readChar(); }
    } catch (IOException e) { /* Impossible */ e.printStackTrace(); System.exit(1); }
    return s.getEndColumn();
  }

}
PARSER_END(Basic)

/***** Default Token Rules *****/

<DEFAULT> SPECIAL_TOKEN :
{
  <COMMENT: ( "//" (~["\n", "\r"])* ("\n" | "\r")
            | "/*" (~["*"] | "*" ~["/"])* "*/")> { parser.comment(matchedToken); }
}

<DEFAULT> SKIP : { " " | "\t" | "\r" | "\n" }

<DEFAULT> TOKEN : 
{
  <RULE: "rule"> : BUBBLE_STATE
| <CONTEXT: "context"> : BUBBLE_STATE
| <CONFIGURATION: "configuration"> : BUBBLE_STATE

| <SYNTAX: "syntax">
| <ENDMODULE: "endmodule">
| <ENDINTERFACE: "endinterface">

| <PRIORITY: "priority"> : KLABEL_STATE
| <PRIORITIES: "priorities"> : KLABEL_STATE
| <NON_ASSOC: "non-assoc"> // : KLABEL_STATE

| <MODULE: "module"> : MODNAME_STATE
| <INTERFACE: "interface"> : MODNAME_STATE
| <IMPORTS: "imports"> : MODNAME_STATE

| <STRING: "\"" (~["\"", "\\", "\n"] |
                 "\\\"" | "\\n" | "\\r" | "\\t" | "\\\\")* "\"">

| <LPAREN: "(">
| <RPAREN: ")">
| <LCURLY: "{">
| <RCURLY: "}">
| <LSQUARE: "[">
| <RSQUARE: "]">

| <GT: ">">
| <PLUS: "+">
| <TIMES: "*">
| <QUESTION: "?">
| <TILDE: "~">
| <COMMA: ",">

| <LEFT: "left">
| <RIGHT: "right">

| "List"
| "NeList"
| "Lexer"
| "Token"

| "require"

| <UPPER_ID: ("#")?["A"-"Z"](["a"-"z", "A"-"Z", "0"-"9"])*>
| <LOWER_ID: ("#")?["a"-"z"](["a"-"z", "A"-"Z", "0"-"9"])*>
}

/** Parses an UPPER_ID token, but also allows List, NeList, Lexer, and
Token unlike the default UPPER_ID.
*/
void UpperId() : {}
{
  <UPPER_ID> | "List" | "NeList" | "Lexer" | "Token"
}

/** Parses a string literal and returns the decoded value of that string. */
String String() : {}
{
  <STRING>
  {
    String s = image();
    return StringUtil.unescape(s.substring(1, s.length() - 1));
  }
}

/** Parses and returns a Sort but not a List, NeList, Lexer, or Token */
Sort SimpleSortID() : { String loc = startLoc(); String str; }
{
  <UPPER_ID> { str = image(); }
  ("{"  { str = str + specialAndImage(); }
   UpperId() { str = str + specialAndImage(); }
   "}"  { str = str + specialAndImage(); })?
  { return markLoc(loc, new Sort(str)); }
}

/** Parses and returns a Sort */
Sort SortID() : { Sort sort; }
{
  sort = SimpleSortID() { return sort; }
  | ("List" | "NeList" | "Lexer" | "Token")
    { return tokenLoc(new Sort(image())); }
}

///////

<MODNAME_STATE> SPECIAL_TOKEN: {
  <MODNAME_COMMENT: <COMMENT>> { parser.comment(matchedToken); } }
<MODNAME_STATE> SKIP: { " " | "\t" | "\r" | "\n" }
<MODNAME_STATE> TOKEN:
{
  <MODNAME: ("#")?(["a"-"z", "0"-"9", "A"-"Z", "_"])+
             ("-" (["a"-"z", "0"-"9", "A"-"Z", "_"])+)*> : DEFAULT
}

/**** String Sentence Bubbles ****/

<BUBBLE_STATE> SPECIAL_TOKEN:
{
  <([" ", "\t", "\r", "\n"])+>
| <BUBBLE_COMMENT: <COMMENT>> { parser.comment(matchedToken); }
}

<BUBBLE_STATE> TOKEN:
{
  "syntax"        { matchedToken.kind = SYNTAX; } : DEFAULT
| "endmodule"     { matchedToken.kind = ENDMODULE; } : DEFAULT
| "endinterface"  { matchedToken.kind = ENDINTERFACE; } : DEFAULT

| "rule"          { matchedToken.kind = RULE;    } : BUBBLE_STATE
| "configuration" { matchedToken.kind = CONFIGURATION;  } : BUBBLE_STATE
| "context"       { matchedToken.kind = CONTEXT; } : BUBBLE_STATE

// Note that "BUBBLE" must be last so it doesn't match keywords
| <BUBBLE: (~[" ", "\t", "\r", "\n"])+>
}

/** Parses and returns an unparsed bubble */
StringSentence Bubble(String type) :
{
  StringBuilder sb = new StringBuilder();
  int sentenceBeginLine = beginLine + token.endLine;
  int sentenceBeginColumn = beginColumn + token.endColumn + 1;
}
{
  (<BUBBLE> { sb.append(image());
              sentenceBeginLine = beginLine + token.beginLine;
              sentenceBeginColumn = beginColumn + token.beginColumn; }
   (<BUBBLE> { sb.append(specialAndImage()); })*)?
  { return makeStringSentence(type, sb.toString(),
      sentenceBeginLine, sentenceBeginColumn); }
}

/**** KLabels ****/

<KLABEL_STATE> SPECIAL_TOKEN: {
  <KLABEL_COMMENT: <COMMENT>> { parser.comment(matchedToken); } }
<KLABEL_STATE> SKIP: { " " | "\t" | "\r" | "\n" }

<KLABEL_STATE> TOKEN:
{
  "syntax"        { matchedToken.kind = SYNTAX; } : DEFAULT
| "endmodule"     { matchedToken.kind = ENDMODULE; } : DEFAULT
| "endinterface"  { matchedToken.kind = ENDINTERFACE; } : DEFAULT

| "rule"          { matchedToken.kind = RULE;    } : BUBBLE_STATE
| "configuration" { matchedToken.kind = CONFIGURATION;  } : BUBBLE_STATE
| "context"       { matchedToken.kind = CONTEXT; } : BUBBLE_STATE

| ">"             { matchedToken.kind = GT; }
| <KLABEL: (~[" ", "\t", "\r", "\n"])+> // Must be last
}

/** Parses a list of KLabels and returns them */
List<KLabelConstant> KLabels() :
{ List<KLabelConstant> list = new ArrayList<KLabelConstant>(); }
{
  // Note that we don't assign location information b/c KLabels are interned
  (<KLABEL> { list.add(KLabelConstant.of(image(), context)); })+
  // TODO: check if need context
  { return list; }
}

/**** RegEx ****/

<REGEX_STATE> SPECIAL_TOKEN: {
  <([" ", "\t", "\r", "\n"])+>
| <REGEX_COMMENT: <COMMENT>> { parser.comment(matchedToken); }
}

<REGEX_STATE> TOKEN:
{
  <ID: ["a"-"z", "A"-"Z"](["a"-"z", "A"-"Z", "0"-"9"])*>
| <REGEX_STRING: <STRING>> { matchedToken.kind = STRING; }
| "(" { matchedToken.kind = LPAREN; }
| ")" { matchedToken.kind = RPAREN; }
| "{" { matchedToken.kind = LCURLY; }
| "}" { matchedToken.kind = RCURLY; }
| "[" { matchedToken.kind = LSQUARE; }
| "]" { matchedToken.kind = RSQUARE; }
| "+" { matchedToken.kind = PLUS; }
| "*" { matchedToken.kind = TIMES; }
| "?" { matchedToken.kind = QUESTION; }
| "~" { matchedToken.kind = TILDE; }
}

/** Parses a complete RegEx and returns it as a String */
String RegEx(StringBuilder follow): { StringBuilder reg = new StringBuilder(); }
{ (Element(reg, follow))+ { return reg.toString(); } }

/** Parses a single RegEx Element and appends it to 'sb' */
void Element(StringBuilder reg, StringBuilder follow) :
{ StringBuilder sb = new StringBuilder(); }
{ { follow.setLength(0); }
( <STRING> { sb.append(specialAndImage()); }
| <ID> { sb.append(specialAndImage()); }
| Group(sb)
| "(" { sb.append(specialAndImage()); }
  (Element(sb, follow))*
  ( "|" { sb.append(specialAndImage()); }
    (Element(sb, follow))*)*
  ")" { sb.append(specialAndImage()); }
/*
| "(" { sb.append(specialAndImage()); }
  (Element(sb, follow))*
  ")" { sb.append(specialAndImage()); }
| "(" { sb.append(specialAndImage()); }
  Element(sb, follow)
  "|" { sb.append(specialAndImage()); }
  Element(sb, follow)
  ")" { sb.append(specialAndImage()); }
*/
| "{" { sb.append(specialAndImage()); }
  Element(sb, follow)
  <STRING> { sb.append(specialAndImage()); }
  "}" { sb.append(specialAndImage()); }
  (("+" | "*") { sb.append(specialAndImage()); })
) ({ follow.setLength(0); }
   (("+" | "*") { follow.append(sb); } | "?")
   { sb.append(specialAndImage()); })*
  { reg.append(sb); }
}

/*** RegEx Character Groups */

<GROUP_STATE> TOKEN:
{ <GROUP: ( ["a"-"z", "A"-"Z", "0"-"9"]
          | "-" | "\t" | "\n" | "\r" | " "
          | "\\" ["t", "n", "r", " "]
          | "\\" ~["a"-"z", "A"-"Z", "\t"])+>
    { if (image.charAt(0) == '-' ||
    		(image.charAt(image.length() - 1) == '-'
    		 && image.charAt(image.length() - 2) != '\\')) {
        throw new TokenMgrError(
          "Lexical error at line " + matchedToken.beginLine +
          ", column " + matchedToken.beginColumn + ". Found \"-\" at " +
          (image.charAt(0) == '-' ? "start" : "end") +
          " of character group in regular expression.",
          TokenMgrError.LEXICAL_ERROR);
      }
    }
}

/** Parses a single character group and appends it to 'sb' */
void Group(StringBuilder sb) : {}
{
  "~"      { sb.append(specialAndImage()); } Group(sb)
| "["      { sb.append(specialAndImage()); SwitchTo(GROUP_STATE); }
  (<GROUP> { sb.append(specialAndImage()); })? { SwitchTo(DEFAULT); }
  "]"      { sb.append(specialAndImage()); }
}

/*** Attributes ***/

<ATTR_STATE> SPECIAL_TOKEN:
{
  "\n" | "\r" | " " | "\t"
| <ATTR_COMMENT: <COMMENT>> { parser.comment(matchedToken); }
}

<ATTR_STATE> TOKEN:
{
  "," { matchedToken.kind = COMMA; }
| "[" { matchedToken.kind = LSQUARE; }
| "]" { matchedToken.kind = RSQUARE; }
| "(" { matchedToken.kind = LPAREN; }
| ")" { matchedToken.kind = RPAREN; }
| <KEY: ["a"-"z","1"-"9"](["A"-"Z", "a"-"z", "-", "0"-"9"])*("<" (["A"-"Z", "a"-"z", "-", "0"-"9"])+ ">")?>
}

/** The same as 'Attributes()', but requires that the entire input be
consumed.  Used for implementing the re-parsing in
makeStringSentence.
*/
void AttributesEOF(ASTNode node) : {} { Attributes(node) <EOF> }
void AttributesBodyEOF(ASTNode node) : {} {
  { SwitchTo(ATTR_STATE); } AttributesBody(node) <EOF> { SwitchTo(DEFAULT); } }

/** Parses a set of attributes and adds them to 'node' */
void AttributesBody(ASTNode node) : {} { Tag(node) ("," Tag(node))* }
void Attributes(ASTNode node) : {}
{
  "[" { SwitchTo(ATTR_STATE); }
  AttributesBody(node)
  "]" { SwitchTo(DEFAULT); }
}

<TAG_STATE> TOKEN:
{
  "(" { matchedToken.kind = LPAREN; }
| ")" { matchedToken.kind = RPAREN; }
| <TAG_STRING: <STRING>> { matchedToken.kind = STRING; }
| <TAG_CONTENT: (~["\n", "\r", "(", ")", "\""])+>
}

/** Parses a single attribute and adds it to 'node' */
void Tag(ASTNode node) :
{ String loc = startLoc(); String key; String val = "";
  StringBuilder sb = new StringBuilder(); }
{
  <KEY> { key = image(); }
  ( "(" { SwitchTo(TAG_STATE); }
    ( val = String() ")"
    | TagContent(sb) ")" { val = sb.toString() + special(); } )
    { SwitchTo(ATTR_STATE); })?
  { node.addAttribute(markLoc(loc, new Attribute(key, val))); }
}

/** Parses the value of an attribute and appends it to 'sb' */
void TagContent(StringBuilder sb) : {}
{
( <TAG_CONTENT> { sb.append(specialAndImage()); }
| "(" { sb.append(specialAndImage()); }
  TagContent(sb)
  ")" { sb.append(specialAndImage()); }
)*
}

/***** MAIN GRAMMAR *****/

/** Parses a file and returns a List of its contents */
List<DefinitionItem> Start() : {}
{
  (Require(items))* (Module(items))* <EOF>
  { return items; }
}

/** Parses a Require clause and adds it to items */
void Require(List<DefinitionItem> items) :
{ String loc = startLoc(); String str; }
{
  "require" str = String() { items.add(markLoc(loc, new Require(str))); }
}

/** Parses a Module and adds it to items */
void Module(List<DefinitionItem> items) : { String loc = startLoc(); }
{
  "module" <MODNAME> { module = new Module(image()); }
    (Import(module))*
    (Sentence(module))*
  "endmodule" {
    // Sort to put comments in order
    Collections.sort(module.getItems(), new EndPositionComparator());
    items.add(markLoc(loc, module));
    module = null; }
}

/** Parses an Import and adds it to module */
void Import(Module module): { String loc = startLoc(); }
{
  "imports" <MODNAME>
  { module.appendModuleItem(markLoc(loc, new Import(image()))); }
}

/** Parses a Sentence and adds it to 'module' */
void Sentence(Module module) :
{ String loc = startLoc(), type, str;
  StringBuilder sb = new StringBuilder();
  Sort sort;
  StringSentence ss;
  List<KLabelConstant> list; }
{
  ("rule" | "context" | "configuration")
  { type = image();
    // Note that we must change the "type"
    if (type.equals("configuration")) { type = "config"; } }
  ss = Bubble(type) { module.appendModuleItem(markLoc(loc, ss)); }

| "syntax"
  ( sort = SortID() { Syntax syn = new Syntax(sort); }
    ( "::=" { List<PriorityBlock> pblocks = new ArrayList<PriorityBlock>(); }
      PriorityBlock(pblocks) (">" PriorityBlock(pblocks))*
      { syn.setPriorityBlocks(pblocks); }
    | Attributes(syn)
    | "-/-" Group(sb) ("." { sb.append(specialAndImage()); } Group(sb))*
      { module.appendModuleItem(markLoc(loc, new Restrictions(
          new Sort(syn.getSort().getRealName()), null, sb.toString()))); return; } )?
    { module.appendModuleItem(markLoc(loc, syn)); }
  
  | ("priority" | "priorities")
      { List<PriorityBlockExtended> pblocks =
          new ArrayList<PriorityBlockExtended>(); }
      list = KLabels() { pblocks.add(new PriorityBlockExtended(list)); }
      (">" list = KLabels() { pblocks.add(new PriorityBlockExtended(list)); })*
    { module.appendModuleItem(markLoc(loc, new PriorityExtended(pblocks))); }
  | ("left" | "right" | "non-assoc") { SwitchTo(KLABEL_STATE); type = image(); }
      list = KLabels()
    { module.appendModuleItem(markLoc(loc, new PriorityExtendedAssoc(type, list))); }
  
  | type = String() "-/-"
      Group(sb) ("." { sb.append(specialAndImage()); } Group(sb))*
      { module.appendModuleItem(markLoc(loc, new Restrictions(
          null, new Terminal(type), sb.toString()))); }
  )
}


/***** Syntax Productions *****/

/** Parses a PriorityBlock and adds it to 'pblocks' */
void PriorityBlock(List<PriorityBlock> pblocks) :
{ String loc = startLoc(); String assoc = "";
  List<Production> prods = new ArrayList<Production>(); }
{
  (("left" | "right" | "non-assoc") { assoc = image(); } ":")?
  Production(prods) ("|" Production(prods))*
  { pblocks.add(markLoc(loc, new PriorityBlock(assoc, prods))); }
}

/** Parses a Production and adds it to 'prods' */
void Production(List<Production> prods) :
{ String loc = startLoc(); Sort sort;
  List<ProductionItem> items = new ArrayList<ProductionItem>();
  String klabel = null; }
{
( LOOKAHEAD((UpperId() | <LOWER_ID>) "(")
  (UpperId() | <LOWER_ID>)
  { items.add(tokenLoc(new Terminal(image()))); klabel = image(); }
  "("              { items.add(tokenLoc(new Terminal(image()))); }
  sort = SortID()  { items.add(sort); }
  (","             { items.add(tokenLoc(new Terminal(image()))); }
   sort = SortID() { items.add(sort); }
  )*
  ")"              { items.add(tokenLoc(new Terminal(image()))); }
| "("              { items.add(tokenLoc(new Terminal(image()))); }
  sort = SortID()  { items.add(sort); }
  (","             { items.add(tokenLoc(new Terminal(image()))); }
   sort = SortID() { items.add(sort); }
  )*
  ")"              { items.add(tokenLoc(new Terminal(image()))); }
| (ProductionItem(items))+
) { Production prod = new Production(new Sort(""), items); }
  (Attributes(prod))?
  { if (klabel != null && prod.getAttribute("klabel") == null) {
      prod.addAttribute("klabel", "'"+klabel);
    }
    prods.add(markLoc(loc, prod)); }
}

/** Parses a ProductionItem and adds it to 'items' */
void ProductionItem(List<ProductionItem> items) :
{ String loc = startLoc(); String str; String sep; Sort sort;
  StringBuilder follow = new StringBuilder(); boolean isToken = false; }
{
  str = String() { items.add(tokenLoc(new Terminal(str))); }
| sort = SimpleSortID() { items.add(sort); }
| "List"
  ( "{" UpperId() { str = image(); } "," sep = String() "}"
    { items.add(markLoc(loc, new UserList(str, sep, "*"))); return; })?
  { items.add(tokenLoc(new Sort(image()))); }
| "NeList"
  ( "{" UpperId() { str = image(); } "," sep = String() "}"
    { items.add(markLoc(loc, new UserList(str, sep, "+"))); return; })?
  { items.add(tokenLoc(new Sort(image()))); }
| ("Lexer" | "Token" { isToken = true; })
  ( "{" { SwitchTo(REGEX_STATE); }
    str = RegEx(follow)
    "}" { SwitchTo(DEFAULT);
          items.add(markLoc(loc, new Lexical(
            str+special(),
            isToken && follow.length() != 0 ?
               follow.toString() : null)));
          return; })?
  { items.add(tokenLoc(new Sort(image()))); }
}
